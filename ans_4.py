# -*- coding: utf-8 -*-
"""ans_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MzDb5oSDE4o4RsSedCZVDSYLghN7xRII

Using a RNN for text analysis on the IMDB dataset
"""

#Just using imports from colab tutorial
from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Embedding, Dropout, Flatten
from keras.layers import LSTM, CuDNNLSTM
from keras.datasets import imdb

from distutils.version import LooseVersion as LV
from keras import __version__
from keras import backend as K

from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

print('Using Keras version:', __version__, 'backend:', K.backend())
assert(LV(__version__) >= LV("2.0.0"))

"""Need to get data and get it into the correct shape to be usable!"""

# using tutorial code to just grab the data and shape it
# determines how many words to sample
number_words = 10000
# cut texts after this number of words
max_len = 80

print('Loading data...')
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=number_words)
print('x_train:', x_train.shape)
print('x_test:', x_test.shape)
print()

x_train = sequence.pad_sequences(x_train, maxlen=max_len)
x_test = sequence.pad_sequences(x_test, maxlen=max_len)
print('x_train shape:', x_train.shape)
print('x_test shape:', x_test.shape)

"""Create super basic model using embedding layer"""

#create base model object
base_model = Sequential()
base_model.add(Embedding(10000, 8, input_length=max_len)) #using the embedding layer to make word embeddings instead of vectorizing the words

base_model.add(Flatten())

base_model.add(Dense(1, activation='sigmoid'))
base_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
base_model.summary()

#run it!
base_history = base_model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

"""We ended up getting validation accuracy of .74 just like in the book!
But now its time to increase performance by using a RNN instead of a Feed-forward network.
"""

#update max_len for the RNN example
max_len = 80
embedding_dims = 50
lstm_units = 32
#recurrent imdb model
r_i_model = Sequential()
r_i_model.add(Embedding(number_words, embedding_dims, input_length=max_len))
r_i_model.add(Dropout(0.2)) #stop overfitting NOW!
r_i_model.add(LSTM(lstm_units)) #this is what makes it an RNN
r_i_model.add(Dense(1, activation='sigmoid'))

r_i_model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])
print(r_i_model.summary())

#LETS GO
epochs = 5
validation_split = 0.2

r_i_history = r_i_model.fit(x_train, y_train, batch_size=128,
          epochs=epochs, 
          validation_split=validation_split)

plt.figure(figsize=(5,3))
plt.plot(r_i_history.epoch,r_i_history.history['loss'], label='training')
plt.plot(r_i_history.epoch,r_i_history.history['val_loss'], label='validation')
plt.title('loss')
plt.legend(loc='best')

plt.figure(figsize=(5,3))
plt.plot(r_i_history.epoch,r_i_history.history['acc'], label='training')
plt.plot(r_i_history.epoch,r_i_history.history['val_acc'], label='validation')
plt.title('accuracy')
plt.legend(loc='best');

"""Looks like 3 epochs is the magic number. But what if we stack LSTM layers?"""

r_model2 = Sequential()
r_model2.add(Embedding(number_words, embedding_dims, input_length=max_len))
r_model2.add(Dropout(0.2))
r_model2.add(LSTM(lstm_units, return_sequences=True))
r_model2.add(LSTM(lstm_units)) #and here... we... go.
r_model2.add(Dense(1, activation='sigmoid'))

r_model2.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])
print(r_model2.summary())
#even with TPU acceleration this takes a while

#training the stacked RNN
r_history2 = r_model2.fit(x_train, y_train, batch_size=128,
          epochs=epochs, 
          validation_split=validation_split)

"""Looks like stacking LSTM layers didn't have a very big effect on performance..."""

plt.clf()
plt.figure(figsize=(5,3))
plt.plot(r_history2.epoch,r_history2.history['loss'], label='training')
plt.plot(r_history2.epoch,r_history2.history['val_loss'], label='validation')
plt.title('loss')
plt.legend(loc='best')

plt.figure(figsize=(5,3))
plt.plot(r_history2.epoch,r_history2.history['acc'], label='training')
plt.plot(r_history2.epoch,r_history2.history['val_acc'], label='validation')
plt.title('accuracy')
plt.legend(loc='best');

"""Looks like 1 epoch is the best here... starts overfitting really fast. Probably should add more dropout layers after the RNNs."""

#Moving onward to the JENA climate dataset! It took a while to get this to work,
#but I eventually had to settle on using my google drive instead of uploading the 
#file itself. If i uploaded the file, it would eventually go through, but whenever
#I would go to open it, the runtime would crash. Using google drive seems to alleviate
#that issue
from google.colab import drive
drive.mount('/content/gdrive')
#need to have file locally downloaded... this takes a while!

f = open('/content/gdrive/My Drive/jena_climate_2009_2016.csv')

data = f.read()
f.close()
lines = data.split('\n')
header = lines[0].split(',')
lines = lines[1:]

print(header)
print(len(lines))

import numpy as np
#create those 420000 or so lines into a numpy array
float_data = np.zeros((len(lines), len(header) - 1))
for i, line in enumerate(lines):
    values = [float(x) for x in line.split(',')[1:]]
    float_data[i, :] = values

#this cell normalizes (standardizes?) the data and creates variables
lookback = 720 # 5 days
steps = 6 # sampling 1 point per hour
delay = 144 # predicting 24 hours in the future
mean = float_data[:200000].mean(axis=0)
float_data -= mean
std = float_data[:200000].std(axis=0)
float_data /= std

"""My lack of compsci knowledge is showing in the next block. There are a few keywords that I don't know what they do, like yield. Apparently its like return, only it returns a generator instead of whatever it is that return returns. The rest of it seems to make sense, but I don't have the programming chops to write something like this from scratch. As an aside, I've never used numpy.randint before (this is my first time seeing it) but its pretty easy to guess what it does."""

def generator(data, lookback, delay, min_index, max_index,
              shuffle=False, batch_size=128, step=6):
    if max_index is None:
        max_index = len(data) - delay - 1
    i = min_index + lookback
    while 1:
        if shuffle:
            rows = np.random.randint(
                min_index + lookback, max_index, size=batch_size)
        else:
            if i + batch_size >= max_index:
                i = min_index + lookback
            rows = np.arange(i, min(i + batch_size, max_index))
            i += len(rows)

        samples = np.zeros((len(rows),
                           lookback // step,
                           data.shape[-1]))
        targets = np.zeros((len(rows),))
        for j, row in enumerate(rows):
            indices = range(rows[j] - lookback, rows[j], step)
            samples[j] = data[indices]
            targets[j] = data[rows[j] + delay][1]
        yield samples, targets

#this block is essentially our train/validation/test split.
lookback = 1440
step = 6
delay = 144
batch_size = 128

train_gen = generator(float_data,
                      lookback=lookback,
                      delay=delay,
                      min_index=0,
                      max_index=200000,
                      shuffle=True,
                      step=step, 
                      batch_size=batch_size)
val_gen = generator(float_data,
                    lookback=lookback,
                    delay=delay,
                    min_index=200001,
                    max_index=300000,
                    step=step,
                    batch_size=batch_size)
test_gen = generator(float_data,
                     lookback=lookback,
                     delay=delay,
                     min_index=300001,
                     max_index=None,
                     step=step,
                     batch_size=batch_size)


val_steps = (300000 - 200001 - lookback) // batch_size


test_steps = (len(float_data) - 300001 - lookback) // batch_size

#adding baseline because its there so why not
def evaluate_naive_method():
    batch_maes = []
    for step in range(val_steps):
        samples, targets = next(val_gen)
        preds = samples[:, -1, 1]
        mae = np.mean(np.abs(preds - targets))
        batch_maes.append(mae)
    print(np.mean(batch_maes))
    
evaluate_naive_method()

#simple machine learning approach
from keras.models import Sequential
from keras import layers
from keras.optimizers import RMSprop

model = Sequential()
model.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1])))
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dense(1))

model.compile(optimizer=RMSprop(), loss='mae')
history = model.fit_generator(train_gen,steps_per_epoch=500,epochs=20,validation_data=val_gen,  validation_steps=val_steps)

"""I stopped the last model because it was taking a while and looked like it started overfitting very early."""

#now we are doing our first recurrent version

model = Sequential()
model.add(layers.GRU(32, input_shape=(None, float_data.shape[-1])))
model.add(layers.Dense(1))

model.compile(optimizer=RMSprop(), loss='mae')
history = model.fit_generator(train_gen, steps_per_epoch=500,epochs=6,validation_data=val_gen,validation_steps=val_steps)

"""Wow. Even a mere 6 epochs took like half an hour to train."""

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(loss))

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

"""You can see it starts to overfit after 6 epochs."""

#A lot of epochs, a lot of time, and recurrent dropout.
model = Sequential()
model.add(layers.GRU(32,dropout=0.2,recurrent_dropout=0.2,input_shape=(None, float_data.shape[-1])))
model.add(layers.Dense(1))

model.compile(optimizer=RMSprop(), loss='mae')
history = model.fit_generator(train_gen,steps_per_epoch=500,epochs=40,validation_data=val_gen,validation_steps=val_steps)

"""I was using a GPU instance instead of a TPU instance, but it still took like 3 hours..."""

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(loss))

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()
#Yep, doesn't look like overfitting is as much of a problem. Global minumum looks
#like 15 epochs though.
model.summary() #the summary was added and run after the next block.
#It was taking forever and wanted to double check if I was using the correct architecture.

"""Now its time to use bidirectional RNNs."""

#New instance, re import
from keras.models import Sequential
from keras import layers
from keras.optimizers import RMSprop
#studying the effects of stacking recurrent layers firsthand... again.
model = Sequential()
model.add(layers.GRU(32,dropout=0.1,recurrent_dropout=0.5,return_sequences=True,input_shape=(None, float_data.shape[-1])))
model.add(layers.GRU(64, activation='relu',dropout=0.1,recurrent_dropout=0.5))
model.add(layers.Dense(1))

model.compile(optimizer=RMSprop(), loss='mae')
history = model.fit_generator(train_gen,steps_per_epoch=500,epochs=40,validation_data=val_gen,validation_steps=val_steps)
#had to

#I HAD TO RUN THIS LAST BLOCK TWICE BECAUSE WINDOWS UPDATE
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(loss))
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()
#moment of truth after like 8 hours

#This new instance (computer turned off again), going to reimport rather than run previous cells again
from keras.models import Sequential
from keras import layers
from keras.optimizers import RMSprop
#features again
max_features = 10000
maxlen = 500
# Need to get the IMDB data back from the beginning, I reload it here.
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
x_test = sequence.pad_sequences(x_test, maxlen=maxlen)
#Create bidirectional RNN to analyze the IMDB dataset
model = Sequential()
model.add(layers.Embedding(max_features, 32))
model.add(layers.Bidirectional(layers.LSTM(32)))
model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)

"""10 epochs of 1 bidirectional RNN layer outperforms 5 epochs of stacked RNNs from before!"""

model = Sequential()
model.add(layers.Bidirectional(layers.GRU(32), input_shape=(None, float_data.shape[-1])))
model.add(layers.Dense(1))
model.compile(optimizer=RMSprop(), loss='mae')
history = model.fit_generator(train_gen,steps_per_epoch=500,epochs=40,validation_data=val_gen,validation_steps=val_steps)
#Applying the bidirectional model to the temperature prediction problem
#Performs slightly worse than the stacked monodirectional RNNS
#Chronological order is therefore important!